#!/usr/bin/env python3

"""
ğŸš€ GPU ENHANCED ULTIMATE OTHELLO AI ğŸš€
GPU ê°€ì† ë²„ì „ì˜ ìµœê°• ì˜¤ë¸ë¡œ AI í”„ë¡œì íŠ¸
"""

import tkinter as tk
from tkinter import messagebox
import sys
import os
import logging
import time
import threading
from pathlib import Path

def setup_main_logging():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¸ì…˜ë³„ ë¡œê¹… ì„¤ì • - ìˆ˜ì •ëœ ë²„ì „"""
    from datetime import datetime
    from pathlib import Path
    import os
    import logging
    
    # logs/main ë””ë ‰í† ë¦¬ ìƒì„± (parents=Trueë¡œ ìƒìœ„ ë””ë ‰í† ë¦¬ë„ í•¨ê»˜ ìƒì„±)
    log_dir = Path("logs") / "main"
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # ì„¸ì…˜ë³„ ê³ ìœ  íƒ€ì„ìŠ¤íƒ¬í”„ ë° ID ìƒì„±
    session_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    session_id = f"session_{session_timestamp}"
    
    # ë‹¤ì–‘í•œ ë¡œê·¸ íŒŒì¼ ìƒì„±
    main_log_file = log_dir / f"Main_{session_id}.log"
    error_log_file = log_dir / f"Errors_{session_id}.log"
    
    # ê¸°ì¡´ ë¡œê¹… ì„¤ì • ì´ˆê¸°í™” (ì¤‘ë³µ ë°©ì§€)
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    # ê¸°ë³¸ ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
        handlers=[
            logging.FileHandler(main_log_file, mode='w', encoding='utf-8'),
            logging.StreamHandler()  # ì½˜ì†” ì¶œë ¥
        ],
        force=True  # ê¸°ì¡´ ì„¤ì • ê°•ì œ ë®ì–´ì“°ê¸°
    )
    
    # ì—ëŸ¬ ì „ìš© ë¡œê±° ì„¤ì •
    error_logger = logging.getLogger('ErrorLogger')
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in error_logger.handlers[:]:
        error_logger.removeHandler(handler)
    
    error_handler = logging.FileHandler(error_log_file, mode='w', encoding='utf-8')
    error_handler.setLevel(logging.ERROR)
    error_formatter = logging.Formatter(
        '%(asctime)s - ERROR - [%(filename)s:%(lineno)d] - %(funcName)s - %(message)s'
    )
    error_handler.setFormatter(error_formatter)
    error_logger.addHandler(error_handler)
    error_logger.propagate = False
    
    # ë©”ì¸ ë¡œê±° ìƒì„±
    logger = logging.getLogger('OthelloGPUMain')
    
    # ë¡œê·¸ íŒŒì¼ ìƒì„± í™•ì¸
    print(f"ğŸ“ Log directory created: {log_dir}")
    print(f"ğŸ“„ Main log file: {main_log_file}")
    print(f"ğŸš¨ Error log file: {error_log_file}")
    
    # ì„¸ì…˜ ì‹œì‘ ì •ë³´ ë¡œê¹…
    logger.info("=" * 80)
    logger.info("ğŸš€ ULTIMATE OTHELLO AI - NEW SESSION")
    logger.info("=" * 80)
    logger.info(f"ğŸ“… Session ID: {session_id}")
    logger.info(f"ğŸ•’ Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"ğŸ“ Main Log: {main_log_file}")
    logger.info(f"ğŸš¨ Error Log: {error_log_file}")
    logger.info(f"ğŸ’» Platform: {os.name}")
    
    # ì‹œìŠ¤í…œ ì •ë³´ ë¡œê¹…
    try:
        import platform
        import sys
        logger.info(f"ğŸ Python: {sys.version}")
        logger.info(f"ğŸ–¥ï¸ System: {platform.system()} {platform.release()}")
        logger.info(f"ğŸ—ï¸ Architecture: {platform.architecture()[0]}")
    except Exception as e:
        logger.warning(f"System info logging failed: {e}")
    
    logger.info("=" * 80)
    
    return logger

# ë©”ì¸ ë¡œê±° ì´ˆê¸°í™”
main_logger = setup_main_logging()


def check_gpu_support():
    """GPU ì§€ì› ì—¬ë¶€ í™•ì¸ ë° ì •ë³´ ì¶œë ¥ - í–¥ìƒëœ ë²„ì „"""
    gpu_info = {
        'cupy_available': False,
        'numba_available': False,
        'cuda_devices': 0,
        'gpu_memory': 0,
        'recommended_backend': 'cpu',
        'error_details': [],
        'cuda_version': 'Unknown'
    }
    
    main_logger.info("ğŸ” GPU ì§€ì› ìƒíƒœ í™•ì¸ ì¤‘...")
    
    # CuPy ìƒì„¸ í™•ì¸
    main_logger.info("1ï¸âƒ£ CuPy í™•ì¸ ì¤‘...")
    try:
        import cupy as cp
        
        # ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
        gpu_info['cuda_devices'] = cp.cuda.runtime.getDeviceCount()
        main_logger.info(f"   CUDA ë””ë°”ì´ìŠ¤ ë°œê²¬: {gpu_info['cuda_devices']}ê°œ")
        
        if gpu_info['cuda_devices'] > 0:
            # ë””ë°”ì´ìŠ¤ ìƒì„¸ ì •ë³´
            device = cp.cuda.Device(0)
            props = cp.cuda.runtime.getDeviceProperties(0)
            gpu_info['gpu_memory'] = device.mem_info[1] // (1024**3)  # GB
            gpu_info['device_name'] = props['name'].decode()
            
            main_logger.info(f"   GPU 0: {gpu_info['device_name']}")
            main_logger.info(f"   GPU ë©”ëª¨ë¦¬: {gpu_info['gpu_memory']} GB")
            
            # CUDA ë²„ì „ í™•ì¸
            try:
                cuda_version = cp.cuda.runtime.runtimeGetVersion()
                gpu_info['cuda_version'] = f"{cuda_version // 1000}.{(cuda_version % 1000) // 10}"
                main_logger.info(f"   CUDA ëŸ°íƒ€ì„ ë²„ì „: {gpu_info['cuda_version']}")
            except Exception as cuda_ver_error:
                gpu_info['error_details'].append(f"CUDA ë²„ì „ í™•ì¸ ì‹¤íŒ¨: {cuda_ver_error}")
            
            # ì‹¤ì œ GPU ì—°ì‚° í…ŒìŠ¤íŠ¸
            main_logger.info("   GPU ì—°ì‚° í…ŒìŠ¤íŠ¸ ì¤‘...")
            try:
                test_array = cp.array([1.0, 2.0, 3.0])
                result = cp.sum(test_array)
                cpu_result = result.get()
                
                if abs(cpu_result - 6.0) < 1e-6:
                    gpu_info['cupy_available'] = True
                    gpu_info['recommended_backend'] = 'cupy'
                    main_logger.info("   âœ… CuPy GPU ì—°ì‚° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                else:
                    raise RuntimeError(f"ì—°ì‚° ê²°ê³¼ ë¶ˆì¼ì¹˜: {cpu_result} != 6.0")
                    
            except Exception as compute_error:
                error_msg = f"CuPy ì—°ì‚° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {compute_error}"
                gpu_info['error_details'].append(error_msg)
                main_logger.warning(f"   âŒ {error_msg}")
        else:
            gpu_info['error_details'].append("CUDA ë””ë°”ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            main_logger.warning("   âŒ CUDA ë””ë°”ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
    except ImportError as import_error:
        error_msg = f"CuPy ëª¨ë“ˆ import ì‹¤íŒ¨: {import_error}"
        gpu_info['error_details'].append(error_msg)
        main_logger.warning(f"   âŒ {error_msg}")
    except Exception as e:
        error_msg = f"CuPy ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
        gpu_info['error_details'].append(error_msg)
        main_logger.warning(f"   âŒ {error_msg}")
    
    # Numba CUDA í™•ì¸
    main_logger.info("2ï¸âƒ£ Numba CUDA í™•ì¸ ì¤‘...")
    try:
        from numba import cuda
        
        if cuda.is_available():
            detected = cuda.detect()
            main_logger.info(f"   Numbaê°€ ê°ì§€í•œ CUDA ë””ë°”ì´ìŠ¤: {detected.count}ê°œ")
            
            try:
                # Numba ì»¨í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸
                ctx = cuda.current_context()
                device_name = ctx.device.name.decode()
                main_logger.info(f"   í˜„ì¬ ë””ë°”ì´ìŠ¤: {device_name}")
                
                gpu_info['numba_available'] = True
                if not gpu_info['cupy_available']:
                    gpu_info['recommended_backend'] = 'numba'
                    
                main_logger.info("   âœ… Numba CUDA ì‚¬ìš© ê°€ëŠ¥!")
                
            except Exception as numba_ctx_error:
                error_msg = f"Numba ì»¨í…ìŠ¤íŠ¸ ì˜¤ë¥˜: {numba_ctx_error}"
                gpu_info['error_details'].append(error_msg)
                main_logger.warning(f"   âŒ {error_msg}")
        else:
            error_msg = "Numbaì—ì„œ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ"
            gpu_info['error_details'].append(error_msg)
            main_logger.warning(f"   âŒ {error_msg}")
            
    except ImportError as numba_import_error:
        error_msg = f"Numba ëª¨ë“ˆ import ì‹¤íŒ¨: {numba_import_error}"
        gpu_info['error_details'].append(error_msg)
        main_logger.warning(f"   âŒ {error_msg}")
    except Exception as numba_error:
        error_msg = f"Numba ì´ˆê¸°í™” ì‹¤íŒ¨: {numba_error}"
        gpu_info['error_details'].append(error_msg)
        main_logger.warning(f"   âŒ {error_msg}")
    
    # ìµœì¢… ì¶”ì²œ ë° ìš”ì•½
    main_logger.info("ğŸ“Š GPU ì§€ì› ìƒíƒœ ìš”ì•½:")
    if gpu_info['cupy_available']:
        main_logger.info(f"ğŸš€ ì¶”ì²œ ë°±ì—”ë“œ: CuPy (CUDA {gpu_info['cuda_version']})")
        main_logger.info(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {gpu_info['gpu_memory']} GB")
        main_logger.info("âš¡ ì„±ëŠ¥: ìµœê³  (GPU ê°€ì† + ê³ ê¸‰ ë©”ëª¨ë¦¬ ê´€ë¦¬)")
    elif gpu_info['numba_available']:
        main_logger.info("ğŸ”¥ ì¶”ì²œ ë°±ì—”ë“œ: Numba CUDA")
        main_logger.info("âš¡ ì„±ëŠ¥: ìš°ìˆ˜ (GPU ê°€ì†)")
    else:
        main_logger.info("ğŸ’» ë°±ì—”ë“œ: CPU ì „ìš©")
        main_logger.info("âš¡ ì„±ëŠ¥: ì–‘í˜¸ (CPU ìµœì í™”)")
        
        if gpu_info['error_details']:
            main_logger.info("âŒ GPU ì‚¬ìš© ë¶ˆê°€ ì›ì¸:")
            for i, error in enumerate(gpu_info['error_details'], 1):
                main_logger.info(f"   {i}. {error}")
            
            main_logger.info("\nğŸ’¡ GPU ì§€ì›ì„ ì›í•œë‹¤ë©´:")
            main_logger.info("   1. NVIDIA GPU ë“œë¼ì´ë²„ ìµœì‹  ë²„ì „ ì„¤ì¹˜")
            main_logger.info("   2. CUDA Toolkit ì„¤ì¹˜ (11.x ë˜ëŠ” 12.x)")
            main_logger.info("   3. CuPy ì„¤ì¹˜: pip install cupy-cuda11x ë˜ëŠ” cupy-cuda12x")
            main_logger.info("   4. ì‹œìŠ¤í…œ ì¬ì‹œì‘ í›„ ë‹¤ì‹œ ì‹œë„")
    
    return gpu_info

def show_gpu_welcome_message(gpu_info):
    """GPU ì§€ì› ì •ë³´ë¥¼ í¬í•¨í•œ í™˜ì˜ ë©”ì‹œì§€ í‘œì‹œ - í–¥ìƒëœ ë²„ì „"""
    if gpu_info['recommended_backend'] in ['cupy', 'numba']:
        # GPU ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
        welcome_msg = f"""
ğŸš€ GPU ENHANCED ULTIMATE OTHELLO AI ğŸš€

ì¶•í•˜í•©ë‹ˆë‹¤! GPU ê°€ì†ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

ğŸ”¥ GPU ì •ë³´:
â€¢ Backend: {gpu_info['recommended_backend'].upper()}
â€¢ CUDA Devices: {gpu_info['cuda_devices']}
â€¢ GPU Memory: {gpu_info['gpu_memory']} GB
â€¢ CUDA Version: {gpu_info['cuda_version']}
â€¢ CuPy Available: {'Yes' if gpu_info['cupy_available'] else 'No'}
â€¢ Numba CUDA: {'Yes' if gpu_info['numba_available'] else 'No'}

âš¡ GPU ê°€ì† ê¸°ëŠ¥:
âœ“ ë³‘ë ¬ ë³´ë“œ í‰ê°€ (10x+ ë¹ ë¦„)
âœ“ ë°°ì¹˜ ì´ë™ ìƒì„± (5x+ ë¹ ë¦„)
âœ“ ê³ ì† transposition table
âœ“ ë²¡í„°í™”ëœ íŒ¨í„´ ì¸ì‹
âœ“ ë³‘ë ¬ ì¢…ë£Œê²Œì„ íƒìƒ‰

âš ï¸ ì£¼ì˜: ì´ AIëŠ” ê·¹ë„ë¡œ ê°•ë ¥í•©ë‹ˆë‹¤!
GPU ê°€ì†ìœ¼ë¡œ ë”ìš± ë¬´ì‹œë¬´ì‹œí•´ì¡ŒìŠµë‹ˆë‹¤.

ì¤€ë¹„ë˜ì…¨ë‚˜ìš”? ğŸ”¥"""
    else:
        # CPUë§Œ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
        welcome_msg = f"""
ğŸ’» ULTIMATE OTHELLO AI (CPU MODE) ğŸ’»

GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì§€ë§Œ ì—¬ì „íˆ ê°•ë ¥í•œ AIì…ë‹ˆë‹¤!

âŒ GPU ì‚¬ìš© ë¶ˆê°€ ì›ì¸:
"""
        for i, error in enumerate(gpu_info['error_details'][:3], 1):  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
            welcome_msg += f"{i}. {error}\n"
        
        welcome_msg += f"""
ğŸ¯ CPU ìµœì í™” ê¸°ëŠ¥:
âœ“ 18-ply ê¹Šì´ íƒìƒ‰
âœ“ ì™„ë²½í•œ ì¢…ë£Œê²Œì„ ì†”ë²„
âœ“ ê³ ê¸‰ í‰ê°€ í•¨ìˆ˜
âœ“ í† ë„ˆë¨¼íŠ¸ê¸‰ ì˜¤í”„ë‹ë¶
âœ“ Alpha-beta ê°€ì§€ì¹˜ê¸°
âœ“ ë°˜ë³µ ì‹¬í™” íƒìƒ‰

ğŸ’¡ GPU ê°€ì†ì„ ì›í•œë‹¤ë©´:
1. NVIDIA GPU ë“œë¼ì´ë²„ ì—…ë°ì´íŠ¸
2. CUDA Toolkit ì„¤ì¹˜ (11.x/12.x)
3. pip install cupy-cuda11x ë˜ëŠ” cupy-cuda12x
4. ì‹œìŠ¤í…œ ì¬ì‹œì‘

ê·¸ë˜ë„ ì´ AIëŠ” ì¶©ë¶„íˆ ê°•ë ¥í•©ë‹ˆë‹¤! ğŸ’ª"""
    
    response = messagebox.askyesno("ğŸ® ULTIMATE CHALLENGE", welcome_msg)
    
    if response:
        main_logger.info("ğŸ® ì‚¬ìš©ìê°€ ë„ì „ì„ ìˆ˜ë½í–ˆìŠµë‹ˆë‹¤!")
    else:
        main_logger.info("ğŸ‘‹ ì‚¬ìš©ìê°€ ë„ì „ì„ ê±°ì ˆí–ˆìŠµë‹ˆë‹¤")
    
    return response

def check_dependencies():
    """í•„ìˆ˜ íŒŒì¼ ë° ì˜ì¡´ì„± í™•ì¸"""
    main_logger.info("ğŸ” Checking dependencies...")
    
    required_files = [
        'constants.py',
        'board.py',
        'ai.py',
        'ultimate_gui.py'
    ]
    
    optional_files = [
        'egaroucid_ai.py',
        'enhanced_board.py',
        'enhanced_gui.py',
        'gpu_board_adapter.py',
        'gpu_ultra_strong_ai.py',
        'training_pipeline.py'
    ]
    
    missing_files = []
    for file in required_files:
        if not os.path.exists(file):
            missing_files.append(file)
            main_logger.error(f"âŒ Missing required file: {file}")
    
    # ì„ íƒì  íŒŒì¼ í™•ì¸
    for file in optional_files:
        if os.path.exists(file):
            main_logger.info(f"âœ… Optional file found: {file}")
        else:
            main_logger.warning(f"âš ï¸ Optional file missing: {file}")
    
    if missing_files:
        error_msg = "âŒ Missing required files:\n\n"
        for file in missing_files:
            error_msg += f"â€¢ {file}\n"
        error_msg += "\nPlease ensure all files are in the same directory."
        messagebox.showerror("Missing Files", error_msg)
        main_logger.error("Dependency check failed")
        return False
    
    main_logger.info("âœ… All dependencies satisfied")
    return True

def check_python_version():
    """Python ë²„ì „ ë° í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸"""
    main_logger.info("ğŸ Checking Python environment...")
    
    # Python ë²„ì „ í™•ì¸
    python_version = sys.version_info
    main_logger.info(f"Python version: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    if python_version < (3, 7):
        messagebox.showerror("Python Version Error",
                           "Python 3.7 or higher is required!\n"
                           f"Current version: {python_version.major}.{python_version.minor}")
        return False
    
    # í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
    required_libs = {
        'tkinter': 'GUI framework',
        'numpy': 'Numerical computing',
        'threading': 'Multi-threading support',
        'hashlib': 'Hashing algorithms',
        'time': 'Time utilities',
        'logging': 'Logging system'
    }
    
    missing_libs = []
    for lib, description in required_libs.items():
        try:
            __import__(lib)
            main_logger.debug(f"âœ… {lib}: {description}")
        except ImportError:
            missing_libs.append(lib)
            main_logger.error(f"âŒ Missing: {lib} ({description})")
    
    if missing_libs:
        error_msg = f"âŒ Missing required libraries:\n\n"
        for lib in missing_libs:
            error_msg += f"â€¢ {lib}\n"
        error_msg += "\nPlease install missing libraries using pip."
        messagebox.showerror("Missing Libraries", error_msg)
        return False
    
    return True

def show_gpu_welcome_message(gpu_info):
    """GPU ì§€ì› ì •ë³´ë¥¼ í¬í•¨í•œ í™˜ì˜ ë©”ì‹œì§€ í‘œì‹œ"""
    if gpu_info['recommended_backend'] != 'cpu':
        # GPU ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
        welcome_msg = f"""
ğŸš€ GPU ENHANCED ULTIMATE OTHELLO AI ğŸš€

ì¶•í•˜í•©ë‹ˆë‹¤! GPU ê°€ì†ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

ğŸ”¥ GPU ì •ë³´:
â€¢ Backend: {gpu_info['recommended_backend'].upper()}
â€¢ CUDA Devices: {gpu_info['cuda_devices']}
â€¢ GPU Memory: {gpu_info['gpu_memory']} GB
â€¢ CuPy Available: {'Yes' if gpu_info['cupy_available'] else 'No'}
â€¢ Numba CUDA: {'Yes' if gpu_info['numba_available'] else 'No'}

âš¡ GPU ê°€ì† ê¸°ëŠ¥:
âœ“ ë³‘ë ¬ ë³´ë“œ í‰ê°€ (10x+ ë¹ ë¦„)
âœ“ ë°°ì¹˜ ì´ë™ ìƒì„± (5x+ ë¹ ë¦„)
âœ“ ê³ ì† transposition table
âœ“ ë²¡í„°í™”ëœ íŒ¨í„´ ì¸ì‹
âœ“ ë³‘ë ¬ ì¢…ë£Œê²Œì„ íƒìƒ‰

âš ï¸ ì£¼ì˜: ì´ AIëŠ” ê·¹ë„ë¡œ ê°•ë ¥í•©ë‹ˆë‹¤!
GPU ê°€ì†ìœ¼ë¡œ ë”ìš± ë¬´ì‹œë¬´ì‹œí•´ì¡ŒìŠµë‹ˆë‹¤.

ì¤€ë¹„ë˜ì…¨ë‚˜ìš”? ğŸ”¥"""
    else:
        # CPUë§Œ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
        welcome_msg = """
ğŸ’» ULTIMATE OTHELLO AI (CPU MODE) ğŸ’»

GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì§€ë§Œ ì—¬ì „íˆ ê°•ë ¥í•œ AIì…ë‹ˆë‹¤!

ğŸ¯ CPU ìµœì í™” ê¸°ëŠ¥:
âœ“ 18-ply ê¹Šì´ íƒìƒ‰
âœ“ ì™„ë²½í•œ ì¢…ë£Œê²Œì„ ì†”ë²„
âœ“ ê³ ê¸‰ í‰ê°€ í•¨ìˆ˜
âœ“ í† ë„ˆë¨¼íŠ¸ê¸‰ ì˜¤í”„ë‹ë¶
âœ“ Alpha-beta ê°€ì§€ì¹˜ê¸°
âœ“ ë°˜ë³µ ì‹¬í™” íƒìƒ‰

ğŸ’¡ GPU ê°€ì†ì„ ì›í•œë‹¤ë©´:
pip install cupy-cuda11x  # CUDA 11.xìš©
ë˜ëŠ”
pip install cupy-cuda12x  # CUDA 12.xìš©

ê·¸ë˜ë„ ì´ AIëŠ” ì¶©ë¶„íˆ ê°•ë ¥í•©ë‹ˆë‹¤! ğŸ’ª"""
    
    response = messagebox.askyesno("ğŸ® ULTIMATE CHALLENGE", welcome_msg)
    
    if response:
        main_logger.info("ğŸ® User accepted the challenge!")
    else:
        main_logger.info("ğŸ‘‹ User declined the challenge")
    
    return response

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì """
    try:
        main_logger.info("ğŸš€ Application startup initiated")
        
        # 1. Python í™˜ê²½ í™•ì¸
        if not check_python_version():
            main_logger.error("Python environment check failed")
            sys.exit(1)
        
        # 2. ì˜ì¡´ì„± í™•ì¸
        if not check_dependencies():
            main_logger.error("Dependency check failed")
            sys.exit(1)
        
        # 3. GPU ì§€ì› í™•ì¸
        gpu_info = check_gpu_support()
        
        # 4. í™˜ì˜ ë©”ì‹œì§€ ë° ì‚¬ìš©ì í™•ì¸
        if not show_gpu_welcome_message(gpu_info):
            main_logger.info("ğŸ‘‹ Application terminated by user choice")
            sys.exit(0)
        
        # 5. GUI ëª¨ë“ˆ import (ì˜ì¡´ì„± í™•ì¸ í›„)
        try:
            from ultimate_gui import UltimateOthelloGUI
            main_logger.info("âœ… GUI module imported successfully")
        except ImportError as e:
            error_msg = f"âŒ GUI Import Error: {e}\n\n"
            error_msg += "Please ensure ultimate_gui.py is in the same directory."
            messagebox.showerror("Import Error", error_msg)
            main_logger.error(f"GUI import failed: {e}")
            sys.exit(1)
        
        # 6. ë©”ì¸ ìœˆë„ìš° ìƒì„±
        main_logger.info("ğŸ® Creating main application window")
        root = tk.Tk()
        
        # ìœˆë„ìš° ì„¤ì •
        root.configure(bg="#0f0f23")
        root.title("ğŸš€ GPU Enhanced Ultimate Othello AI")
        
        # 7. GUI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
        main_logger.info("ğŸ® Initializing game interface...")
        app = UltimateOthelloGUI(root)
        
        # 8. ì—°ì† í•™ìŠµ ëª¨ë“œ ì„¤ì • (GUI ìƒì„± í›„)
        try:
            from training_pipeline import TrainingPipeline
            pipeline = TrainingPipeline()
            
            # GUIì— í•™ìŠµ ê¸°ëŠ¥ ì¶”ê°€
            if hasattr(app, 'enable_learning_mode'):
                learning_callback = pipeline.continuous_learning_mode()
                app.enable_learning_mode(learning_callback)
                main_logger.info("ğŸ”¥ Learning mode activated")
            else:
                main_logger.warning("GUI does not support learning mode")
        except ImportError as e:
            main_logger.warning(f"Training pipeline not available: {e}")
        
        # 9. GPU ì •ë³´ë¥¼ GUIì— ì „ë‹¬ (GUIê°€ ì§€ì›í•œë‹¤ë©´)
        if hasattr(app, 'set_gpu_info'):
            app.set_gpu_info(gpu_info)
            main_logger.info("ğŸ”¥ GPU information passed to GUI")
        
        # 10. ì‹œì‘ ì™„ë£Œ ë¡œê·¸
        main_logger.info("ğŸš€ Game interface ready!")
        main_logger.info("ğŸ’¡ Tips for playing:")
        main_logger.info(" â€¢ GPU ê°€ì†ìœ¼ë¡œ ë” ê¹Šì€ íƒìƒ‰ ê°€ëŠ¥")
        main_logger.info(" â€¢ ë” ì •í™•í•œ ìœ„ì¹˜ í‰ê°€")
        main_logger.info(" â€¢ ë¹ ë¥¸ ì¢…ë£Œê²Œì„ ê³„ì‚°")
        main_logger.info(" â€¢ Good luck... you'll need it! ğŸ˜ˆ")
        main_logger.info("=" * 60)
        
        # 11. GUI ì´ë²¤íŠ¸ ë£¨í”„ ì‹œì‘
        main_logger.info("â–¶ï¸ Starting GUI event loop")
        root.mainloop()
        
        main_logger.info("ğŸ Application terminated normally")
        
    except KeyboardInterrupt:
        main_logger.info("âŒ¨ï¸ Application interrupted by user (Ctrl+C)")
        sys.exit(0)
    except ImportError as e:
        error_msg = f"âŒ Import Error: {e}\n\n"
        error_msg += "Please ensure all Python files are in the same directory\n"
        error_msg += "and that there are no syntax errors in the code."
        messagebox.showerror("Import Error", error_msg)
        main_logger.error(f"Import error: {e}")
        sys.exit(1)
    except Exception as e:
        error_msg = f"âŒ Unexpected Error: {e}\n\n"
        error_msg += "Please check the log file for more details.\n"
        error_msg += f"Log location: logs/othello_gpu_ai_*.log"
        messagebox.showerror("Unexpected Error", error_msg)
        main_logger.error(f"Unexpected error: {e}", exc_info=True)
        sys.exit(1)
    finally:
        # ì •ë¦¬ ì‘ì—…
        try:
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            try:
                import cupy as cp
                cp.get_default_memory_pool().free_all_blocks()
                main_logger.info("ğŸ§¹ GPU memory cleaned up")
            except:
                pass
            
            main_logger.info("ğŸ‘‹ Thanks for playing GPU Enhanced Ultimate Othello AI!")
        except Exception as e:
            main_logger.error(f"Cleanup error: {e}")

if __name__ == "__main__":
    # ëª…ë ¹ì¤„ ì¸ìˆ˜ ì²˜ë¦¬
    if len(sys.argv) > 1:
        if sys.argv[1] == "--help":
            print("""
ğŸš€ GPU Enhanced Ultimate Othello AI

Usage:
  python gpu_ultimate_main.py        # Normal game mode
  python gpu_ultimate_main.py --help # Show this help

Features:
ğŸ”¥ GPU acceleration with CuPy/Numba
âš¡ 18-ply depth search
ğŸ§  Perfect endgame solver
ğŸ“Š Real-time performance monitoring
ğŸ¯ Tournament-level AI

Requirements:
- Python 3.7+
- tkinter (GUI)
- numpy (computation)
- cupy or numba (GPU acceleration, optional)

For best performance, install GPU support:
  pip install cupy-cuda11x  # For CUDA 11.x
  pip install cupy-cuda12x  # For CUDA 12.x
""")
        else:
            print(f"Unknown argument: {sys.argv[1]}")
            print("Use --help for usage information")
    else:
        # ì¼ë°˜ ì‹¤í–‰
        main()
