import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import time
from collections import deque
import logging
import os
import datetime
from datetime import datetime

def setup_training_logger():
    """ì„¸ì…˜ë³„ Training Pipeline ë¡œê±° ì„¤ì •"""
    log_dir = "logs/training"
    os.makedirs(log_dir, exist_ok=True)
    
    # ì„¸ì…˜ë³„ ê³ ìœ  íƒ€ì„ìŠ¤íƒ¬í”„
    session_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    session_id = f"session_{session_timestamp}"
    
    # ë¡œê·¸ íŒŒì¼ëª… ìƒì„±
    log_filename = f"Training_{session_id}.log"
    log_filepath = os.path.join(log_dir, log_filename)
    
    logger = logging.getLogger('TrainingPipeline')
    logger.setLevel(logging.INFO)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ë§Œ ì¶”ê°€ (ìƒˆ íŒŒì¼)
    file_handler = logging.FileHandler(log_filepath, mode='w', encoding='utf-8')
    
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
    )
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    logger.propagate = False
    
    # ì„¸ì…˜ ì‹œì‘ ë¡œê·¸
    logger.info("=" * 60)
    logger.info(f"ğŸ“ TRAINING SESSION STARTED: {session_id}")
    logger.info(f"ğŸ“ Log File: {log_filepath}")
    logger.info("=" * 60)
    
    return logger

logger = setup_training_logger()

# ì•ˆì „í•œ GPU ëª¨ë“ˆ import
try:
    from gpu_ultra_strong_ai import (
        UltraStrongAI, GPUSelfPlayTrainer, GPUManager, 
        GPUOthelloNet, BLACK, WHITE
    )
    GPU_MODULES_AVAILABLE = True
except ImportError as e:
    GPU_MODULES_AVAILABLE = False
    logger.warning(f"GPU ëª¨ë“ˆì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    
    # ë°±ì—… ìƒìˆ˜
    BLACK = 1
    WHITE = 2

class TrainingPipeline:
    """AlphaZero ìŠ¤íƒ€ì¼ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ - ì•ˆì •í™” ë²„ì „"""
    
    def __init__(self, model_dir='models', device=None, auto_save_interval=5):
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = device
            
        self.model_dir = model_dir
        os.makedirs(model_dir, exist_ok=True)
        
        # ìë™ ì €ì¥ ê°„ê²© ì„¤ì •
        self.auto_save_interval = auto_save_interval
        self.game_counter = 0
        self.training_data = deque(maxlen=50000)
        
        # ì•ˆì „í•œ íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
        self._safe_initialize_trainer()
        
        logger.info(f"í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {self.device})")

    def _safe_initialize_trainer(self):
        """ì•ˆì „í•œ íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”"""
        self.gpu_available = False
        
        try:
            if (GPU_MODULES_AVAILABLE and 
                torch.cuda.is_available() and 
                GPUManager and GPUOthelloNet and GPUSelfPlayTrainer):
                
                # GPU íŠ¸ë ˆì´ë„ˆ ì‚¬ìš©
                self.gpu_manager = GPUManager()
                if self.gpu_manager.gpu_available:
                    self.neural_net = GPUOthelloNet().to(self.device)
                    self.trainer = GPUSelfPlayTrainer(self.neural_net, self.gpu_manager)
                    self.gpu_available = True
                    logger.info("GPU íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    raise RuntimeError("GPU ë§¤ë‹ˆì €ê°€ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤ê³  ë³´ê³ ")
        except Exception as e:
            logger.warning(f"GPU íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
        # GPU ì‹¤íŒ¨ì‹œ CPU ë°±ì—…
        if not self.gpu_available:
            try:
                self.neural_net = self._create_simple_neural_net()
                self.optimizer = optim.Adam(self.neural_net.parameters(), lr=0.001)
                self.loss_fn = nn.MSELoss()
                self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.9)
                logger.info("CPU íŠ¸ë ˆì´ë„ˆë¡œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"CPU íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")
                # ìµœì†Œí•œì˜ ë”ë¯¸ êµ¬í˜„
                self.neural_net = None
                self.optimizer = None
                self.loss_fn = None
                self.scheduler = None

    def _create_simple_neural_net(self):
        """ê°„ë‹¨í•œ ì‹ ê²½ë§ ìƒì„± (GPU ëª¨ë“ˆì´ ì—†ì„ ë•Œ ì‚¬ìš©)"""
        class SimpleOthelloNet(nn.Module):
            def __init__(self):
                super().__init__()
                self.conv1 = nn.Conv2d(3, 64, 3, padding=1)
                self.conv2 = nn.Conv2d(64, 128, 3, padding=1)
                self.conv3 = nn.Conv2d(128, 256, 3, padding=1)
                
                # ì •ì±… í—¤ë“œ (64ê°œ ì•¡ì…˜)
                self.policy_head = nn.Sequential(
                    nn.Conv2d(256, 32, 1),
                    nn.ReLU(),
                    nn.Flatten(),
                    nn.Linear(32 * 8 * 8, 64),
                    nn.LogSoftmax(dim=1)  # CrossEntropyLoss ì‚¬ìš©ì„ ìœ„í•´ LogSoftmax ì‚¬ìš©
                )
                
                # ê°€ì¹˜ í—¤ë“œ
                self.value_head = nn.Sequential(
                    nn.Conv2d(256, 16, 1),
                    nn.ReLU(),
                    nn.Flatten(),
                    nn.Linear(16 * 8 * 8, 256),
                    nn.ReLU(),
                    nn.Linear(256, 1),
                    nn.Tanh()
                )

            def forward(self, x):
                x = torch.relu(self.conv1(x))
                x = torch.relu(self.conv2(x))
                x = torch.relu(self.conv3(x))
                
                policy = self.policy_head(x)
                value = self.value_head(x)
                
                return policy, value

        return SimpleOthelloNet().to(self.device)

    def continuous_learning_mode(self):
        """ì—°ì† í•™ìŠµ ëª¨ë“œ ì½œë°± ë°˜í™˜ - ì•ˆì „í•œ ë²„ì „"""
        logger.info("ğŸ“ ì—°ì† í•™ìŠµ ëª¨ë“œ ì‹œì‘")
        
        def safe_post_game_callback(game_data):
            """ì•ˆì „í•œ ê²Œì„ ì™„ë£Œ ì½œë°±"""
            try:
                if not game_data or not self.neural_net:
                    return
                
                # ê²Œì„ ë°ì´í„°ë¥¼ ì‹ ê²½ë§ í›ˆë ¨ ë°ì´í„°ë¡œ ë³€í™˜
                training_data = self.safe_convert_game_data(game_data)
                
                if training_data:
                    self.training_data.extend(training_data)
                    self.game_counter += 1
                    
                    # ì¼ì • ê²Œì„ë§ˆë‹¤ í•™ìŠµ ì‹¤í–‰
                    if self.game_counter % self.auto_save_interval == 0:
                        logger.info(f"ğŸ“ {self.game_counter}ê²Œì„ ì™„ë£Œ, í•™ìŠµ ì‹œì‘...")
                        
                        # ì•ˆì „í•œ í•™ìŠµ ì‹¤í–‰
                        if self._safe_train_neural_network():
                            # ëª¨ë¸ ìë™ ì €ì¥
                            model_path = f"{self.model_dir}/auto_save_{self.game_counter}.pth"
                            if self._safe_save_model(model_path):
                                logger.info(f"âœ… ìë™ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ: {model_path}")
                            else:
                                logger.warning("ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨")
                        else:
                            logger.warning("í•™ìŠµ ì‹¤íŒ¨")
                    
            except Exception as e:
                logger.error(f"âŒ í•™ìŠµ ì½œë°± ì˜¤ë¥˜: {e}")
        
        return safe_post_game_callback
    
    def safe_convert_game_data(self, game_data):
        """ì•ˆì „í•œ ê²Œì„ ë°ì´í„° ë³€í™˜ - ê°•í™”ëœ ë²„ì „"""
        try:
            training_data = []
            
            for data in game_data:
                try:
                    # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
                    if not isinstance(data, dict):
                        continue
                        
                    # í•„ìˆ˜ í‚¤ í™•ì¸
                    required_keys = ['board', 'move', 'color']
                    if not all(key in data for key in required_keys):
                        continue
                    
                    # ë³´ë“œ ìƒíƒœë¥¼ í…ì„œë¡œ ë³€í™˜
                    board_tensor = self.safe_board_to_tensor(data.get('board'), data.get('color'))
                    
                    if board_tensor is not None:
                        # ì •ì±… (ì‹¤ì œ ìˆ˜ë¥¼ ì¸ë±ìŠ¤ë¡œ)
                        move = data.get('move')
                        if move and len(move) >= 2:
                            x, y = move[0], move[1]
                            # ì¢Œí‘œ ìœ íš¨ì„± ê²€ì‚¬
                            if 0 <= x < 8 and 0 <= y < 8:
                                move_idx = x * 8 + y
                                value = float(data.get('value', 0.0))
                                # ê°’ ë²”ìœ„ ì œí•œ
                                value = max(-1.0, min(1.0, value))
                                training_data.append((board_tensor, move_idx, value))
                        
                except Exception as e:
                    logger.debug(f"ê°œë³„ ë°ì´í„° ë³€í™˜ ì˜¤ë¥˜: {e}")
                    continue
            
            logger.debug(f"ë³€í™˜ëœ í›ˆë ¨ ë°ì´í„°: {len(training_data)}ê°œ")
            return training_data
            
        except Exception as e:
            logger.error(f"ê²Œì„ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}")
            return []

    def safe_board_to_tensor(self, board_array, color):
        """ì•ˆì „í•œ ë³´ë“œ í…ì„œ ë³€í™˜ - ê°•í™”ëœ ë²„ì „"""
        try:
            if not board_array or not color:
                return None
            
            # ë³´ë“œ ë°°ì—´ ìœ íš¨ì„± ê²€ì‚¬
            if not isinstance(board_array, (list, np.ndarray)):
                return None
            
            # 8x8 í¬ê¸° í™•ì¸
            if len(board_array) != 8:
                return None
                
            tensor = torch.zeros(3, 8, 8, dtype=torch.float32)
            
            for i in range(8):
                if not isinstance(board_array[i], (list, np.ndarray)) or len(board_array[i]) != 8:
                    continue
                    
                for j in range(8):
                    try:
                        cell_value = board_array[i][j]
                        
                        # ì…€ ê°’ ìœ íš¨ì„± ê²€ì‚¬
                        if cell_value == color:
                            tensor[0][i][j] = 1.0
                        elif cell_value != 0 and cell_value != color:  # ìƒëŒ€ë°© ëŒ
                            tensor[1][i][j] = 1.0
                    except (IndexError, TypeError, ValueError):
                        continue
            
            # í˜„ì¬ í”Œë ˆì´ì–´ ì •ë³´
            if color == BLACK:
                tensor[2] = torch.ones(8, 8)
            
            return tensor
            
        except Exception as e:
            logger.debug(f"ë³´ë“œ í…ì„œ ë³€í™˜ ì˜¤ë¥˜: {e}")
            return None
    
    def _safe_train_neural_network(self):
        """ì•ˆì „í•œ ì‹ ê²½ë§ í›ˆë ¨"""
        try:
            if len(self.training_data) < 32:
                logger.debug("í›ˆë ¨ ë°ì´í„° ë¶€ì¡±")
                return False
                
            if self.gpu_available and hasattr(self.trainer, 'train_neural_net'):
                # GPU íŠ¸ë ˆì´ë„ˆ ì‚¬ìš©
                try:
                    self.trainer.train_neural_net(batch_size=32, epochs=2)
                    return True
                except Exception as e:
                    logger.error(f"GPU í›ˆë ¨ ì‹¤íŒ¨: {e}")
                    return False
            elif self.neural_net and self.optimizer:
                # CPU íŠ¸ë ˆì´ë„ˆ ì‚¬ìš©
                return self._safe_train_cpu_model()
            else:
                logger.warning("í›ˆë ¨ ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
                return False
                
        except Exception as e:
            logger.error(f"ì‹ ê²½ë§ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            return False
    
    def _safe_train_cpu_model(self):
        """ì•ˆì „í•œ CPU ëª¨ë¸ í›ˆë ¨ - ê°œì„ ëœ ë²„ì „"""
        try:
            if not self.neural_net or not self.optimizer or len(self.training_data) < 16:
                return False
            
            batch_size = 16
            epochs = 2
            
            # ì•ˆì „í•œ ë°ì´í„° ìƒ˜í”Œë§
            sample_data = list(self.training_data)[-min(1000, len(self.training_data)):]
            
            self.neural_net.train()
            total_loss = 0
            batches = 0
            
            for epoch in range(epochs):
                epoch_loss = 0
                epoch_batches = 0
                
                for i in range(0, len(sample_data), batch_size):
                    batch = sample_data[i:i+batch_size]
                    if len(batch) < batch_size // 2:  # ìµœì†Œ ì ˆë°˜ì€ ìœ íš¨í•´ì•¼ í•¨
                        continue
                    
                    try:
                        # ì•ˆì „í•œ ë°°ì¹˜ ì²˜ë¦¬
                        boards = []
                        policies = []
                        values = []
                        
                        for item in batch:
                            try:
                                if len(item) >= 3:
                                    boards.append(item[0])
                                    policies.append(item[1])
                                    values.append(item[2])
                            except (IndexError, TypeError):
                                continue
                        
                        if len(boards) < batch_size // 4:  # ìµœì†Œ 1/4ì€ ìœ íš¨í•´ì•¼ í•¨
                            continue
                        
                        # í…ì„œ ë³€í™˜
                        boards_tensor = torch.stack(boards[:len(boards)]).to(self.device)
                        
                        # ì •ì±…ì„ ì›í•«ì—ì„œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
                        policy_indices = []
                        for p in policies[:len(boards)]:
                            if isinstance(p, (int, np.integer)):
                                # ì´ë¯¸ ì¸ë±ìŠ¤ì¸ ê²½ìš°
                                policy_indices.append(min(63, max(0, int(p))))
                            elif isinstance(p, (list, np.ndarray)):
                                # ì›í•« ë²¡í„°ì¸ ê²½ìš°
                                try:
                                    idx = np.argmax(p) if len(p) > 0 else 0
                                    policy_indices.append(min(63, max(0, int(idx))))
                                except:
                                    policy_indices.append(0)
                            else:
                                policy_indices.append(0)
                        
                        policies_tensor = torch.tensor(policy_indices, dtype=torch.long).to(self.device)
                        values_tensor = torch.tensor(values[:len(boards)], dtype=torch.float32).unsqueeze(1).to(self.device)
                        
                        # í›ˆë ¨ ë‹¨ê³„
                        self.optimizer.zero_grad()
                        pred_policies, pred_values = self.neural_net(boards_tensor)
                        
                        # ì†ì‹¤ ê³„ì‚°
                        policy_loss = nn.CrossEntropyLoss()(pred_policies, policies_tensor)
                        value_loss = self.loss_fn(pred_values, values_tensor)
                        total_loss_batch = policy_loss + value_loss
                        
                        # ì—­ì „íŒŒ
                        total_loss_batch.backward()
                        torch.nn.utils.clip_grad_norm_(self.neural_net.parameters(), 1.0)
                        self.optimizer.step()
                        
                        epoch_loss += total_loss_batch.item()
                        epoch_batches += 1
                        
                    except Exception as batch_error:
                        logger.debug(f"ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {batch_error}")
                        continue
                
                if epoch_batches > 0:
                    total_loss += epoch_loss / epoch_batches
                    batches += 1
                    logger.debug(f"Epoch {epoch+1}/{epochs}, ë°°ì¹˜: {epoch_batches}, í‰ê·  ì†ì‹¤: {epoch_loss/epoch_batches:.4f}")
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
            if self.scheduler:
                self.scheduler.step()
            
            if batches > 0:
                avg_loss = total_loss / batches
                logger.info(f"CPU ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ - í‰ê·  ì†ì‹¤: {avg_loss:.4f}")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"CPU ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            return False
    
    def _safe_save_model(self, model_path):
        """ì•ˆì „í•œ ëª¨ë¸ ì €ì¥"""
        try:
            if self.gpu_available and hasattr(self.trainer, 'save_model'):
                self.trainer.save_model(model_path)
                return True
            elif self.neural_net and self.optimizer:
                checkpoint = {
                    'model_state_dict': self.neural_net.state_dict(),
                    'game_counter': self.game_counter
                }
                
                if self.optimizer:
                    checkpoint['optimizer_state_dict'] = self.optimizer.state_dict()
                    
                if hasattr(self, 'scheduler') and self.scheduler:
                    checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()
                
                torch.save(checkpoint, model_path)
                return True
            else:
                logger.warning("ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
                return False
                
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def load_model(self, model_path):
        """ëª¨ë¸ ë¡œë“œ - ê°œì„ ëœ ë²„ì „"""
        try:
            if not os.path.exists(model_path):
                logger.warning(f"ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
                return False
                
            if self.gpu_available and hasattr(self.trainer, 'load_model'):
                return self.trainer.load_model(model_path)
            elif self.neural_net:
                checkpoint = torch.load(model_path, map_location=self.device)
                
                # ëª¨ë¸ ìƒíƒœ ë¡œë“œ
                if 'model_state_dict' in checkpoint:
                    self.neural_net.load_state_dict(checkpoint['model_state_dict'])
                
                # ì˜µí‹°ë§ˆì´ì € ìƒíƒœ ë¡œë“œ
                if self.optimizer and 'optimizer_state_dict' in checkpoint:
                    try:
                        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                    except Exception as e:
                        logger.warning(f"ì˜µí‹°ë§ˆì´ì € ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ë¡œë“œ
                if (hasattr(self, 'scheduler') and self.scheduler and 
                    'scheduler_state_dict' in checkpoint):
                    try:
                        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
                    except Exception as e:
                        logger.warning(f"ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # ê²Œì„ ì¹´ìš´í„° ë¡œë“œ
                self.game_counter = checkpoint.get('game_counter', 0)
                
                logger.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
                return True
            else:
                logger.error("ë¡œë“œí•  ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return False
                
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def get_training_stats(self):
        """í›ˆë ¨ í†µê³„ ë°˜í™˜"""
        stats = {
            'game_counter': self.game_counter,
            'training_data_size': len(self.training_data),
            'gpu_available': self.gpu_available,
            'device': str(self.device)
        }
        
        if self.gpu_available and hasattr(self.trainer, 'training_stats'):
            stats.update(self.trainer.training_stats)
        
        return stats
    
    def manual_training_step(self, num_epochs=5, batch_size=32):
        """ìˆ˜ë™ í›ˆë ¨ ë‹¨ê³„ ì‹¤í–‰"""
        logger.info(f"ìˆ˜ë™ í›ˆë ¨ ì‹œì‘: {num_epochs} epochs, batch_size={batch_size}")
        
        if len(self.training_data) < batch_size:
            logger.warning(f"í›ˆë ¨ ë°ì´í„° ë¶€ì¡±: {len(self.training_data)} < {batch_size}")
            return False
        
        try:
            if self.gpu_available and hasattr(self.trainer, 'train_neural_net'):
                self.trainer.train_neural_net(batch_size=batch_size, epochs=num_epochs)
                return True
            elif self.neural_net and self.optimizer:
                # CPU í›ˆë ¨ ì‹¤í–‰
                return self._safe_train_cpu_model()
            else:
                logger.error("í›ˆë ¨ ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
                return False
                
        except Exception as e:
            logger.error(f"ìˆ˜ë™ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            return False
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.gpu_available and hasattr(self, 'gpu_manager'):
                self.gpu_manager.clear_memory()
                logger.info("GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            logger.debug(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    pipeline = TrainingPipeline()
    
    # ê¸°ì¡´ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë¡œë“œ
    best_model_path = 'models/best_model.pth'
    if os.path.exists(best_model_path):
        logger.info("ê¸°ì¡´ ëª¨ë¸ ë°œê²¬, ë¡œë“œí•©ë‹ˆë‹¤.")
        pipeline.load_model(best_model_path)
    else:
        logger.info("ìƒˆë¡œìš´ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
    # ì—°ì† í•™ìŠµ ëª¨ë“œ ì½œë°± ìƒì„±
    learning_callback = pipeline.continuous_learning_mode()
    
    logger.info("í›ˆë ¨ íŒŒì´í”„ë¼ì¸ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    logger.info("GUIì—ì„œ ê²Œì„ì„ ì‹œì‘í•˜ë©´ ìë™ìœ¼ë¡œ í•™ìŠµì´ ì§„í–‰ë©ë‹ˆë‹¤.")
    
    return pipeline, learning_callback

if __name__ == "__main__":
    main()